{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20190813cnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CharlesPoletowin/YCBS-273/blob/master/20190813cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAOfh2YSUuyo",
        "colab_type": "text"
      },
      "source": [
        "# try implement cnn model from pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLdByit6U2iK",
        "colab_type": "text"
      },
      "source": [
        "## import lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1QNaeWw0Ktz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import gzip\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfiu8CjmU-lL",
        "colab_type": "text"
      },
      "source": [
        "## the original model cnn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLfNmA-t0U1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class mycnn(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=(2, 2), stride=2, padding=0)\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), padding=0)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=(2, 2), stride=1, padding=0)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), padding=0)\n",
        "\n",
        "    self.fc_layer=nn.Linear(72,10)\n",
        "\n",
        "  def forward(self, xb):\n",
        "    xb = self.conv1(xb)\n",
        "    xb = self.pool1(xb)\n",
        "    xb = F.relu(xb)\n",
        "\n",
        "    xb = self.conv2(xb)\n",
        "    xb = self.pool2(xb)\n",
        "    xb = F.relu(xb)\n",
        "\n",
        "    xb = xb.view(-1,72)  # reshape\n",
        "\n",
        "    xb = self.fc_layer(xb)\n",
        "    \n",
        "    return xb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KsMIx8F6xO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, x_train, y_train, x_test, y_test, epochs=250, batch_size=64, lr=0.01, weight_decay=0):\n",
        "  # data\n",
        "  train_dataset = TensorDataset(x_train, y_train)\n",
        "  train_data_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "  \n",
        "  # loss function\n",
        "  loss_func = F.cross_entropy\n",
        "\n",
        "  # optimizer\n",
        "  optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "  # training loop\n",
        "  for epoch in range(epochs):\n",
        "    for xb, yb in train_data_loader:\n",
        "      \n",
        "      pred = model(xb)\n",
        "      loss = loss_func(pred, yb)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    y_pred = model(x_test)\n",
        "    acc = accuracy_score(torch.argmax(y_pred, dim=1).cpu().detach().numpy(), y_test.cpu())\n",
        "    \n",
        "    print('Loss at epoch %d : %f, test acc: %f' % (epoch, loss, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTGfwWE7VDgv",
        "colab_type": "text"
      },
      "source": [
        "## prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_oaCG058NyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = Path(\"data\")\n",
        "PATH = DATA_PATH / \"mnist\"\n",
        "\n",
        "PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def get_data(url, file_name, offset):\n",
        "  content = requests.get(url).content\n",
        "  (PATH / file_name).open(\"wb\").write(content)\n",
        "  with gzip.open((PATH / file_name).as_posix(), \"rb\") as f:\n",
        "    data = np.frombuffer(f.read(), dtype=np.uint8, offset=offset)\n",
        "  return data\n",
        "\n",
        "y_train = get_data(\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\", \"train-labels\", 8).astype('int64')\n",
        "x_train = get_data(\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\", \"train-images\", 16).reshape(len(y_train), 784).astype('float32')\n",
        "y_test = get_data(\"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\", \"test-labels\", 8).astype('int64')\n",
        "x_test = get_data(\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\", \"test-images\", 16).reshape(len(y_test), 784).astype('float32')\n",
        "x_train, y_train, x_test, y_test = map(\n",
        "    torch.tensor, (x_train, y_train, x_test, y_test)\n",
        ")\n",
        "n = x_train.shape[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URLI5G6FVIXu",
        "colab_type": "text"
      },
      "source": [
        "### cuda available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXlA4_vA9Jm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test=x_test.cuda()\n",
        "x_train=x_train.cuda()\n",
        "y_test=y_test.cuda()\n",
        "y_train=y_train.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV9tvavx9U33",
        "colab_type": "code",
        "outputId": "56fcd637-053c-4364-8bd5-99ed2c82ded3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "mycnn1= mycnn()\n",
        "mycnn1.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mycnn(\n",
              "  (conv1): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(4, 8, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc_layer): Linear(in_features=72, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoGb4IjJ9iDS",
        "colab_type": "code",
        "outputId": "a6c4c8ee-090c-484d-bdcf-6fe248dac240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "source": [
        "train_model(mycnn1, x_train.view(-1,1,28,28), y_train, x_test.view(-1,1,28,28), y_test,epochs=30,lr=0.0001)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at epoch 0 : 1.746233, test acc: 0.474800\n",
            "Loss at epoch 1 : 1.291562, test acc: 0.585600\n",
            "Loss at epoch 2 : 1.192207, test acc: 0.621900\n",
            "Loss at epoch 3 : 1.116498, test acc: 0.642300\n",
            "Loss at epoch 4 : 1.044503, test acc: 0.656400\n",
            "Loss at epoch 5 : 0.973766, test acc: 0.670800\n",
            "Loss at epoch 6 : 0.888933, test acc: 0.684900\n",
            "Loss at epoch 7 : 0.816667, test acc: 0.699000\n",
            "Loss at epoch 8 : 0.757497, test acc: 0.715800\n",
            "Loss at epoch 9 : 0.697233, test acc: 0.729500\n",
            "Loss at epoch 10 : 0.654854, test acc: 0.743300\n",
            "Loss at epoch 11 : 0.623112, test acc: 0.755800\n",
            "Loss at epoch 12 : 0.599370, test acc: 0.767900\n",
            "Loss at epoch 13 : 0.581345, test acc: 0.779400\n",
            "Loss at epoch 14 : 0.567804, test acc: 0.786000\n",
            "Loss at epoch 15 : 0.557630, test acc: 0.794200\n",
            "Loss at epoch 16 : 0.543983, test acc: 0.799900\n",
            "Loss at epoch 17 : 0.533080, test acc: 0.803600\n",
            "Loss at epoch 18 : 0.522023, test acc: 0.808000\n",
            "Loss at epoch 19 : 0.510665, test acc: 0.815300\n",
            "Loss at epoch 20 : 0.499249, test acc: 0.818600\n",
            "Loss at epoch 21 : 0.490387, test acc: 0.821900\n",
            "Loss at epoch 22 : 0.478951, test acc: 0.826500\n",
            "Loss at epoch 23 : 0.468801, test acc: 0.829700\n",
            "Loss at epoch 24 : 0.457729, test acc: 0.830800\n",
            "Loss at epoch 25 : 0.444439, test acc: 0.834500\n",
            "Loss at epoch 26 : 0.433131, test acc: 0.837000\n",
            "Loss at epoch 27 : 0.419850, test acc: 0.841800\n",
            "Loss at epoch 28 : 0.408279, test acc: 0.846200\n",
            "Loss at epoch 29 : 0.394238, test acc: 0.848500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcQWyBBW9pY0",
        "colab_type": "code",
        "outputId": "fb599edf-fecf-413e-b05a-af697f04193d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "source": [
        "train_model(mycnn1, x_train.view(-1,1,28,28), y_train, x_test.view(-1,1,28,28), y_test,epochs=30,lr=0.0001)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at epoch 0 : 0.383708, test acc: 0.852600\n",
            "Loss at epoch 1 : 0.375363, test acc: 0.854500\n",
            "Loss at epoch 2 : 0.365329, test acc: 0.856500\n",
            "Loss at epoch 3 : 0.357541, test acc: 0.858500\n",
            "Loss at epoch 4 : 0.346006, test acc: 0.860200\n",
            "Loss at epoch 5 : 0.334956, test acc: 0.862900\n",
            "Loss at epoch 6 : 0.325281, test acc: 0.864900\n",
            "Loss at epoch 7 : 0.314016, test acc: 0.868300\n",
            "Loss at epoch 8 : 0.304550, test acc: 0.869200\n",
            "Loss at epoch 9 : 0.295908, test acc: 0.869800\n",
            "Loss at epoch 10 : 0.289075, test acc: 0.871500\n",
            "Loss at epoch 11 : 0.282735, test acc: 0.873900\n",
            "Loss at epoch 12 : 0.279076, test acc: 0.875000\n",
            "Loss at epoch 13 : 0.272357, test acc: 0.875700\n",
            "Loss at epoch 14 : 0.267530, test acc: 0.876800\n",
            "Loss at epoch 15 : 0.261419, test acc: 0.878800\n",
            "Loss at epoch 16 : 0.258070, test acc: 0.880100\n",
            "Loss at epoch 17 : 0.254905, test acc: 0.880500\n",
            "Loss at epoch 18 : 0.252003, test acc: 0.881800\n",
            "Loss at epoch 19 : 0.249199, test acc: 0.882500\n",
            "Loss at epoch 20 : 0.245282, test acc: 0.883800\n",
            "Loss at epoch 21 : 0.240832, test acc: 0.884600\n",
            "Loss at epoch 22 : 0.236420, test acc: 0.884900\n",
            "Loss at epoch 23 : 0.232609, test acc: 0.886200\n",
            "Loss at epoch 24 : 0.228144, test acc: 0.887700\n",
            "Loss at epoch 25 : 0.225337, test acc: 0.888300\n",
            "Loss at epoch 26 : 0.221439, test acc: 0.888600\n",
            "Loss at epoch 27 : 0.217652, test acc: 0.888400\n",
            "Loss at epoch 28 : 0.210672, test acc: 0.889200\n",
            "Loss at epoch 29 : 0.206259, test acc: 0.890200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5V71dlMEOgj",
        "colab_type": "code",
        "outputId": "9655cc05-5ec7-46bd-de31-257a8a66feeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "source": [
        "train_model(mycnn1, x_train.view(-1,1,28,28), y_train, x_test.view(-1,1,28,28), y_test,epochs=30,lr=0.0001)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at epoch 0 : 0.199632, test acc: 0.890600\n",
            "Loss at epoch 1 : 0.193213, test acc: 0.891800\n",
            "Loss at epoch 2 : 0.188237, test acc: 0.893400\n",
            "Loss at epoch 3 : 0.184487, test acc: 0.894100\n",
            "Loss at epoch 4 : 0.180569, test acc: 0.894600\n",
            "Loss at epoch 5 : 0.177181, test acc: 0.895600\n",
            "Loss at epoch 6 : 0.173735, test acc: 0.896300\n",
            "Loss at epoch 7 : 0.170623, test acc: 0.896700\n",
            "Loss at epoch 8 : 0.168641, test acc: 0.897700\n",
            "Loss at epoch 9 : 0.167001, test acc: 0.898600\n",
            "Loss at epoch 10 : 0.166416, test acc: 0.899200\n",
            "Loss at epoch 11 : 0.165784, test acc: 0.899100\n",
            "Loss at epoch 12 : 0.165009, test acc: 0.899700\n",
            "Loss at epoch 13 : 0.165316, test acc: 0.900300\n",
            "Loss at epoch 14 : 0.166102, test acc: 0.900800\n",
            "Loss at epoch 15 : 0.166592, test acc: 0.901100\n",
            "Loss at epoch 16 : 0.167382, test acc: 0.902400\n",
            "Loss at epoch 17 : 0.167557, test acc: 0.902800\n",
            "Loss at epoch 18 : 0.168183, test acc: 0.903500\n",
            "Loss at epoch 19 : 0.167581, test acc: 0.904400\n",
            "Loss at epoch 20 : 0.167333, test acc: 0.904800\n",
            "Loss at epoch 21 : 0.167599, test acc: 0.905600\n",
            "Loss at epoch 22 : 0.167817, test acc: 0.906000\n",
            "Loss at epoch 23 : 0.168624, test acc: 0.906000\n",
            "Loss at epoch 24 : 0.168996, test acc: 0.906600\n",
            "Loss at epoch 25 : 0.169378, test acc: 0.906800\n",
            "Loss at epoch 26 : 0.169352, test acc: 0.906800\n",
            "Loss at epoch 27 : 0.169376, test acc: 0.907100\n",
            "Loss at epoch 28 : 0.169313, test acc: 0.907300\n",
            "Loss at epoch 29 : 0.169630, test acc: 0.907300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwznge1OVODV",
        "colab_type": "text"
      },
      "source": [
        "## try new cnn model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlDsTxLXEfss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class mycnnNew(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "        \n",
        "      self.features = nn.Sequential(\n",
        "          nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "          nn.BatchNorm2d(32),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "          nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "      )\n",
        "        \n",
        "      self.classifier = nn.Sequential(\n",
        "          nn.Dropout(p = 0.5),\n",
        "          nn.Linear(64 * 7 * 7, 512),\n",
        "          nn.BatchNorm1d(512),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Dropout(p = 0.5),\n",
        "          nn.Linear(512, 512),\n",
        "          nn.BatchNorm1d(512),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Dropout(p = 0.5),\n",
        "          nn.Linear(512, 10),\n",
        "      )\n",
        "        \n",
        "      for m in self.features.children():\n",
        "          if isinstance(m, nn.Conv2d):\n",
        "              n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "              m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "          elif isinstance(m, nn.BatchNorm2d):\n",
        "              m.weight.data.fill_(1)\n",
        "              m.bias.data.zero_()\n",
        "      \n",
        "      for m in self.classifier.children():\n",
        "          if isinstance(m, nn.Linear):\n",
        "              nn.init.xavier_uniform(m.weight)\n",
        "          elif isinstance(m, nn.BatchNorm1d):\n",
        "              m.weight.data.fill_(1)\n",
        "              m.bias.data.zero_()\n",
        "                \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        \n",
        "        return x     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qMqKNjLHMS7",
        "colab_type": "code",
        "outputId": "7d674517-cfc1-4201-8489-31ec069a8802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        }
      },
      "source": [
        "mycnn2= mycnnNew()\n",
        "mycnn2.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mycnnNew(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU(inplace)\n",
              "    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5)\n",
              "    (1): Linear(in_features=3136, out_features=512, bias=True)\n",
              "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): ReLU(inplace)\n",
              "    (4): Dropout(p=0.5)\n",
              "    (5): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): ReLU(inplace)\n",
              "    (8): Dropout(p=0.5)\n",
              "    (9): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRmwvUaHHbRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, x_train, y_train, x_test, y_test, epochs=250, batch_size=256, lr=0.01, weight_decay=0):\n",
        "  # data\n",
        "  train_dataset = TensorDataset(x_train, y_train)\n",
        "  train_data_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "  \n",
        "  # loss function\n",
        "  loss_func = F.cross_entropy\n",
        "\n",
        "  # optimizer\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "  # training loop\n",
        "  for epoch in range(epochs):\n",
        "    for xb, yb in train_data_loader:\n",
        "      \n",
        "      pred = model(xb)\n",
        "      loss = loss_func(pred, yb)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    y_pred = model(x_test)\n",
        "    acc = accuracy_score(torch.argmax(y_pred, dim=1).cpu().detach().numpy(), y_test.cpu())\n",
        "    \n",
        "    print('Loss at epoch %d : %f, test acc: %f' % (epoch, loss, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PFMuhGwHTuh",
        "colab_type": "code",
        "outputId": "fcfa8852-e006-495e-9722-fa3f4dce40e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "train_model(mycnn2, x_train.view(-1,1,28,28), y_train, x_test.view(-1,1,28,28), y_test,epochs=30,lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at epoch 0 : 0.024664, test acc: 0.980600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-be315823241f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmycnn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-a71be1d83070>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, x_train, y_train, x_test, y_test, epochs, batch_size, lr, weight_decay)\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-3f094084ebb1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 958.00 MiB (GPU 0; 11.17 GiB total capacity; 8.92 GiB already allocated; 887.88 MiB free; 539.65 MiB cached)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEbDUEEcVXXI",
        "colab_type": "text"
      },
      "source": [
        "## try new cnn model2 without fully connected layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXvHCRt8Kg7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class mycnnNew2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=(2, 2), stride=2, padding=0)\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), padding=0)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=(2, 2), stride=1, padding=0)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), padding=0)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=8, out_channels=10, kernel_size=(2, 2), stride=1, padding=0)\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=(2, 2), padding=0)\n",
        "\n",
        "  def forward(self, xb):\n",
        "    xb = self.conv1(xb)\n",
        "    xb = self.pool1(xb)\n",
        "    xb = F.relu(xb)\n",
        "\n",
        "    xb = self.conv2(xb)\n",
        "    xb = self.pool2(xb)\n",
        "    xb = F.relu(xb)\n",
        "\n",
        "    xb = self.conv3(xb)\n",
        "    xb = self.pool3(xb)\n",
        "    xb = F.relu(xb)\n",
        "\n",
        "    xb = xb.view(-1,10)  # reshape\n",
        "    \n",
        "    return xb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVNWsBVcMssw",
        "colab_type": "code",
        "outputId": "e481303e-0d3d-4ebf-ccee-74ff5d09b97a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "mycnn2= mycnnNew2()\n",
        "mycnn2.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mycnnNew2(\n",
              "  (conv1): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(4, 8, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(8, 10, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipTyIxJgMxIH",
        "colab_type": "code",
        "outputId": "683df712-c17d-49bd-d351-1668e9c86dcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        }
      },
      "source": [
        "train_model(mycnn2, x_train.view(-1,1,28,28), y_train, x_test.view(-1,1,28,28), y_test,epochs=30,lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at epoch 0 : 1.294848, test acc: 0.657200\n",
            "Loss at epoch 1 : 0.966768, test acc: 0.752900\n",
            "Loss at epoch 2 : 0.588402, test acc: 0.796900\n",
            "Loss at epoch 3 : 0.384869, test acc: 0.821300\n",
            "Loss at epoch 4 : 0.299969, test acc: 0.827000\n",
            "Loss at epoch 5 : 0.266450, test acc: 0.832100\n",
            "Loss at epoch 6 : 0.253402, test acc: 0.835300\n",
            "Loss at epoch 7 : 0.275465, test acc: 0.839900\n",
            "Loss at epoch 8 : 0.303268, test acc: 0.842600\n",
            "Loss at epoch 9 : 0.319065, test acc: 0.845300\n",
            "Loss at epoch 10 : 0.313331, test acc: 0.848000\n",
            "Loss at epoch 11 : 0.313610, test acc: 0.850300\n",
            "Loss at epoch 12 : 0.297781, test acc: 0.852200\n",
            "Loss at epoch 13 : 0.288426, test acc: 0.853600\n",
            "Loss at epoch 14 : 0.289039, test acc: 0.853700\n",
            "Loss at epoch 15 : 0.295336, test acc: 0.855900\n",
            "Loss at epoch 16 : 0.294172, test acc: 0.856300\n",
            "Loss at epoch 17 : 0.281977, test acc: 0.857600\n",
            "Loss at epoch 18 : 0.279066, test acc: 0.856100\n",
            "Loss at epoch 19 : 0.274937, test acc: 0.854400\n",
            "Loss at epoch 20 : 0.266525, test acc: 0.853600\n",
            "Loss at epoch 21 : 0.266555, test acc: 0.855000\n",
            "Loss at epoch 22 : 0.260042, test acc: 0.855000\n",
            "Loss at epoch 23 : 0.256298, test acc: 0.855400\n",
            "Loss at epoch 24 : 0.246785, test acc: 0.854400\n",
            "Loss at epoch 25 : 0.254454, test acc: 0.856500\n",
            "Loss at epoch 26 : 0.253351, test acc: 0.855600\n",
            "Loss at epoch 27 : 0.248053, test acc: 0.855900\n",
            "Loss at epoch 28 : 0.249941, test acc: 0.856500\n",
            "Loss at epoch 29 : 0.252744, test acc: 0.856600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfI0Q33rVjGw",
        "colab_type": "text"
      },
      "source": [
        "## try cnn new model3 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puJT8XIkMzg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class mycnnNew3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(2, 2), stride=2, padding=0)\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), padding=0)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(2, 2), stride=1, padding=0)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), padding=0)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(2, 2), stride=1, padding=0)\n",
        "    self.pool3 = nn.MaxPool2d(kernel_size=(2, 2), padding=0)\n",
        "\n",
        "  def forward(self, xb):\n",
        "    xb = self.conv1(xb)\n",
        "    xb = self.pool1(xb)\n",
        "    xb = F.relu(xb)\n",
        "\n",
        "    xb = self.conv2(xb)\n",
        "    xb = self.pool2(xb)\n",
        "    xb = F.relu(xb)\n",
        "\n",
        "    xb = self.conv3(xb)\n",
        "    xb = self.pool3(xb)\n",
        "    xb = F.relu(xb)\n",
        "\n",
        "    xb = xb.view(-1,10)  # reshape\n",
        "    \n",
        "    return xb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz6duflQNvkh",
        "colab_type": "code",
        "outputId": "9653934f-af79-4e85-bf39-82cdfa38dc7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "mycnn3= mycnnNew3()\n",
        "mycnn3.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mycnnNew3(\n",
              "  (conv1): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(4, 8, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(8, 8, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (conv4): Conv2d(8, 10, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (pool4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KycYsVJgNxv7",
        "colab_type": "code",
        "outputId": "694f610d-ae5c-4310-b9af-85d4413fa791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        }
      },
      "source": [
        "train_model(mycnn3, x_train.view(-1,1,28,28), y_train, x_test.view(-1,1,28,28), y_test,epochs=30,lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at epoch 0 : 0.841792, test acc: 0.650700\n",
            "Loss at epoch 1 : 0.503979, test acc: 0.740000\n",
            "Loss at epoch 2 : 0.276702, test acc: 0.809200\n",
            "Loss at epoch 3 : 0.314182, test acc: 0.823900\n",
            "Loss at epoch 4 : 0.286516, test acc: 0.828400\n",
            "Loss at epoch 5 : 0.246339, test acc: 0.832300\n",
            "Loss at epoch 6 : 0.231269, test acc: 0.838400\n",
            "Loss at epoch 7 : 0.223435, test acc: 0.840200\n",
            "Loss at epoch 8 : 0.221031, test acc: 0.840300\n",
            "Loss at epoch 9 : 0.226826, test acc: 0.841300\n",
            "Loss at epoch 10 : 0.216865, test acc: 0.840500\n",
            "Loss at epoch 11 : 0.205376, test acc: 0.840200\n",
            "Loss at epoch 12 : 0.185354, test acc: 0.846300\n",
            "Loss at epoch 13 : 0.168543, test acc: 0.848000\n",
            "Loss at epoch 14 : 0.159415, test acc: 0.848300\n",
            "Loss at epoch 15 : 0.154316, test acc: 0.848200\n",
            "Loss at epoch 16 : 0.150831, test acc: 0.849700\n",
            "Loss at epoch 17 : 0.159984, test acc: 0.852600\n",
            "Loss at epoch 18 : 0.154055, test acc: 0.853500\n",
            "Loss at epoch 19 : 0.151885, test acc: 0.852900\n",
            "Loss at epoch 20 : 0.154190, test acc: 0.853700\n",
            "Loss at epoch 21 : 0.159818, test acc: 0.854300\n",
            "Loss at epoch 22 : 0.153453, test acc: 0.854300\n",
            "Loss at epoch 23 : 0.160482, test acc: 0.855100\n",
            "Loss at epoch 24 : 0.157739, test acc: 0.855100\n",
            "Loss at epoch 25 : 0.157914, test acc: 0.855200\n",
            "Loss at epoch 26 : 0.162271, test acc: 0.855300\n",
            "Loss at epoch 27 : 0.167984, test acc: 0.856100\n",
            "Loss at epoch 28 : 0.166585, test acc: 0.856300\n",
            "Loss at epoch 29 : 0.165854, test acc: 0.857000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kuJzQguVv8a",
        "colab_type": "text"
      },
      "source": [
        "## try new cnn model4 improve avgpool2d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9yMBxZ6N3wG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class mycnnNew4(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(2, 2), stride=2, padding=0)\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), padding=0)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(2, 2), stride=1, padding=0)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), padding=0)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(2, 2), stride=1, padding=0)\n",
        "    self.pool3 = nn.AvgPool2d(kernel_size=(2, 2), padding=0)\n",
        "\n",
        "  def forward(self, xb):\n",
        "    xb = self.conv1(xb)\n",
        "    xb = self.pool1(xb)\n",
        "    xb = F.leaky_relu(xb)\n",
        "\n",
        "    xb = self.conv2(xb)\n",
        "    xb = self.pool2(xb)\n",
        "    xb = F.leaky_relu(xb)\n",
        "\n",
        "    xb = self.conv3(xb)\n",
        "    xb = self.pool3(xb)\n",
        "    xb = F.leaky_relu(xb)\n",
        "\n",
        "    xb = xb.view(-1,10)  # reshape\n",
        "    \n",
        "    return xb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO3HH4mrQbWC",
        "colab_type": "code",
        "outputId": "44576f66-805c-4ece-97c4-4d462d3fb2c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "mycnn4= mycnnNew4()\n",
        "mycnn4.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mycnnNew4(\n",
              "  (conv1): Conv2d(1, 8, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(8, 16, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(16, 10, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (pool3): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkFgnyvpQg3k",
        "colab_type": "code",
        "outputId": "81f0d67f-34b9-4f75-dcde-9534e1eb60ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        }
      },
      "source": [
        "train_model(mycnn4, x_train.view(-1,1,28,28), y_train, x_test.view(-1,1,28,28), y_test,epochs=30,lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at epoch 0 : 2.079775, test acc: 0.289800\n",
            "Loss at epoch 1 : 1.795111, test acc: 0.393100\n",
            "Loss at epoch 2 : 1.538747, test acc: 0.531300\n",
            "Loss at epoch 3 : 1.232358, test acc: 0.663300\n",
            "Loss at epoch 4 : 0.631396, test acc: 0.821700\n",
            "Loss at epoch 5 : 0.554915, test acc: 0.852800\n",
            "Loss at epoch 6 : 0.466510, test acc: 0.871800\n",
            "Loss at epoch 7 : 0.407404, test acc: 0.884600\n",
            "Loss at epoch 8 : 0.372852, test acc: 0.894700\n",
            "Loss at epoch 9 : 0.335485, test acc: 0.902800\n",
            "Loss at epoch 10 : 0.316834, test acc: 0.909700\n",
            "Loss at epoch 11 : 0.303526, test acc: 0.914100\n",
            "Loss at epoch 12 : 0.288920, test acc: 0.917000\n",
            "Loss at epoch 13 : 0.279811, test acc: 0.920100\n",
            "Loss at epoch 14 : 0.268737, test acc: 0.924100\n",
            "Loss at epoch 15 : 0.259610, test acc: 0.925100\n",
            "Loss at epoch 16 : 0.249873, test acc: 0.927800\n",
            "Loss at epoch 17 : 0.243584, test acc: 0.930400\n",
            "Loss at epoch 18 : 0.238489, test acc: 0.931200\n",
            "Loss at epoch 19 : 0.233559, test acc: 0.932400\n",
            "Loss at epoch 20 : 0.227727, test acc: 0.933300\n",
            "Loss at epoch 21 : 0.222552, test acc: 0.934300\n",
            "Loss at epoch 22 : 0.215232, test acc: 0.935500\n",
            "Loss at epoch 23 : 0.209091, test acc: 0.937200\n",
            "Loss at epoch 24 : 0.205130, test acc: 0.937700\n",
            "Loss at epoch 25 : 0.199514, test acc: 0.938300\n",
            "Loss at epoch 26 : 0.194331, test acc: 0.938400\n",
            "Loss at epoch 27 : 0.190702, test acc: 0.939300\n",
            "Loss at epoch 28 : 0.190943, test acc: 0.939800\n",
            "Loss at epoch 29 : 0.188823, test acc: 0.939900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6yae49oV8-3",
        "colab_type": "text"
      },
      "source": [
        "## try cnn new model5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "813bKMVFQlwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class mycnnNew5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=(2, 2), stride=2, padding=0)\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), padding=0)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channels=2, out_channels=5, kernel_size=(2, 2), stride=1, padding=0)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), padding=0)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=(2, 2), stride=1, padding=1)\n",
        "    self.pool3 = nn.AvgPool2d(kernel_size=(2, 2), padding=0)\n",
        "\n",
        "  def forward(self, xb):\n",
        "    xb = self.conv1(xb)\n",
        "    xb = self.pool1(xb)\n",
        "    xb = F.leaky_relu(xb)\n",
        "\n",
        "    xb = self.conv2(xb)\n",
        "    xb = self.pool2(xb)\n",
        "    xb = F.leaky_relu(xb)\n",
        "\n",
        "    xb = self.conv3(xb)\n",
        "    xb = self.pool3(xb)\n",
        "    xb = F.leaky_relu(xb)\n",
        "\n",
        "    xb = xb.view(-1,10)  # reshape\n",
        "    \n",
        "    return xb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_mjsn02UR6t",
        "colab_type": "code",
        "outputId": "1e4dbd88-3916-4140-866c-b3c69765ba98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "mycnn5 = mycnnNew5()\n",
        "mycnn5.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mycnnNew5(\n",
              "  (conv1): Conv2d(1, 2, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(2, 5, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(5, 10, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
              "  (pool3): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK79MqatUVre",
        "colab_type": "code",
        "outputId": "3eadef4f-3339-4ab8-cb00-0a703ca42d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "train_model(mycnn5, x_train.view(-1,1,28,28), y_train, x_test.view(-1,1,28,28), y_test,epochs=30,lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-733595385427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmycnn5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-07645ebde907>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, x_train, y_train, x_test, y_test, epochs, batch_size, lr, weight_decay)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2054\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1867\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1868\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[0;32m-> 1869\u001b[0;31m                          .format(input.size(0), target.size(0)))\n\u001b[0m\u001b[1;32m   1870\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (1024) to match target batch_size (256)."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD-dxbBgWk3B",
        "colab_type": "text"
      },
      "source": [
        "## summarize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQQwmzZYUZzJ",
        "colab_type": "code",
        "outputId": "de307805-c10c-490e-cd57-687c10e401e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "list(mycnnNew.parameters(mycnn2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[[[ 0.0769, -0.1252],\n",
              "           [ 0.1644, -0.0865]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0918,  0.0525],\n",
              "           [-0.0318,  0.0551]]],\n",
              " \n",
              " \n",
              "         [[[-0.0019, -0.1170],\n",
              "           [-0.1328, -0.2068]]],\n",
              " \n",
              " \n",
              "         [[[-0.0667, -0.1217],\n",
              "           [ 0.0988,  0.0707]]]], device='cuda:0', requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0052, -0.0009, -0.1874, -0.0051], device='cuda:0',\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[[[-0.0599, -0.0715],\n",
              "           [-0.0180, -0.0408]],\n",
              " \n",
              "          [[-0.0755, -0.1858],\n",
              "           [ 0.0995,  0.1057]],\n",
              " \n",
              "          [[-0.0839, -0.0528],\n",
              "           [-0.1902, -0.0899]],\n",
              " \n",
              "          [[ 0.2481,  0.2178],\n",
              "           [ 0.0613,  0.0429]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0442, -0.0330],\n",
              "           [-0.0565, -0.0597]],\n",
              " \n",
              "          [[ 0.0829, -0.0599],\n",
              "           [ 0.2859,  0.2950]],\n",
              " \n",
              "          [[ 0.0983,  0.1306],\n",
              "           [-0.1690,  0.1080]],\n",
              " \n",
              "          [[-0.0123,  0.0940],\n",
              "           [ 0.0414,  0.1103]]],\n",
              " \n",
              " \n",
              "         [[[-0.0020, -0.0514],\n",
              "           [-0.0275, -0.0806]],\n",
              " \n",
              "          [[ 0.2136,  0.3312],\n",
              "           [-0.1278, -0.1431]],\n",
              " \n",
              "          [[-0.1079,  0.2306],\n",
              "           [ 0.0246,  0.1690]],\n",
              " \n",
              "          [[ 0.0411,  0.0102],\n",
              "           [ 0.1009,  0.1302]]],\n",
              " \n",
              " \n",
              "         [[[-0.1237,  0.0186],\n",
              "           [-0.2630,  0.0779]],\n",
              " \n",
              "          [[ 0.0311,  0.1636],\n",
              "           [-0.0501,  0.2080]],\n",
              " \n",
              "          [[-0.2477, -0.1349],\n",
              "           [-0.0338,  0.1326]],\n",
              " \n",
              "          [[ 0.0459, -0.0283],\n",
              "           [ 0.1989, -0.0459]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0553,  0.0342],\n",
              "           [ 0.1580, -0.0065]],\n",
              " \n",
              "          [[ 0.2693, -0.0520],\n",
              "           [ 0.0720, -0.0901]],\n",
              " \n",
              "          [[-0.0023, -0.1288],\n",
              "           [ 0.1377, -0.1680]],\n",
              " \n",
              "          [[-0.1053, -0.0367],\n",
              "           [-0.4701, -0.1813]]],\n",
              " \n",
              " \n",
              "         [[[-0.1312,  0.0293],\n",
              "           [-0.4405, -0.2246]],\n",
              " \n",
              "          [[ 0.0715,  0.2092],\n",
              "           [-0.0529, -0.1756]],\n",
              " \n",
              "          [[-0.0119,  0.1873],\n",
              "           [-0.2247,  0.0938]],\n",
              " \n",
              "          [[ 0.0060, -0.0203],\n",
              "           [-0.5768, -0.2862]]],\n",
              " \n",
              " \n",
              "         [[[ 0.1027, -0.0563],\n",
              "           [ 0.1943,  0.0445]],\n",
              " \n",
              "          [[ 0.0829,  0.0006],\n",
              "           [ 0.0936, -0.0313]],\n",
              " \n",
              "          [[-0.0071,  0.0502],\n",
              "           [-0.0443,  0.1518]],\n",
              " \n",
              "          [[-0.0305,  0.0598],\n",
              "           [ 0.0415,  0.0437]]],\n",
              " \n",
              " \n",
              "         [[[-0.1567, -0.3798],\n",
              "           [ 0.0928,  0.1019]],\n",
              " \n",
              "          [[-0.2237,  0.0266],\n",
              "           [ 0.2722, -0.1170]],\n",
              " \n",
              "          [[-0.0948,  0.0033],\n",
              "           [-0.0441,  0.0951]],\n",
              " \n",
              "          [[-0.1337, -0.3262],\n",
              "           [ 0.0260,  0.0245]]]], device='cuda:0', requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.5120, -2.0583,  0.1776, -0.3147,  0.3437,  2.1951, -2.4335,  0.3106],\n",
              "        device='cuda:0', requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[[[-0.1652, -0.4797],\n",
              "           [ 0.0343, -0.1357]],\n",
              " \n",
              "          [[-0.1627,  0.1859],\n",
              "           [ 0.2457, -0.2336]],\n",
              " \n",
              "          [[ 0.2159, -0.0278],\n",
              "           [ 0.0892,  0.2271]],\n",
              " \n",
              "          [[-0.2605,  0.1255],\n",
              "           [-0.2264, -0.1721]],\n",
              " \n",
              "          [[ 0.3493,  0.1442],\n",
              "           [-0.0611,  0.4111]],\n",
              " \n",
              "          [[-0.1290, -0.0576],\n",
              "           [ 0.1822,  0.0793]],\n",
              " \n",
              "          [[ 0.2587,  0.0522],\n",
              "           [-0.0278, -0.3143]],\n",
              " \n",
              "          [[ 0.0059, -0.2449],\n",
              "           [-0.0585, -0.1977]]],\n",
              " \n",
              " \n",
              "         [[[-0.2812, -0.0490],\n",
              "           [ 0.1389, -0.1275]],\n",
              " \n",
              "          [[ 0.0742, -0.0270],\n",
              "           [ 0.0510,  0.1149]],\n",
              " \n",
              "          [[-0.1169, -0.3800],\n",
              "           [-0.3232,  0.1630]],\n",
              " \n",
              "          [[-0.0866,  0.5936],\n",
              "           [-0.2430,  0.3324]],\n",
              " \n",
              "          [[-0.4163,  0.1276],\n",
              "           [ 0.1776,  0.4385]],\n",
              " \n",
              "          [[-0.0505, -0.0579],\n",
              "           [ 0.2612, -0.0532]],\n",
              " \n",
              "          [[ 0.0337, -0.2343],\n",
              "           [-0.7868, -0.3543]],\n",
              " \n",
              "          [[ 0.2841,  0.0388],\n",
              "           [ 0.0125, -0.0255]]],\n",
              " \n",
              " \n",
              "         [[[ 0.1989, -0.3111],\n",
              "           [-0.0962,  0.2777]],\n",
              " \n",
              "          [[-0.0301,  0.2431],\n",
              "           [ 0.0405, -0.0644]],\n",
              " \n",
              "          [[ 0.1658, -0.1666],\n",
              "           [ 0.1189,  0.1295]],\n",
              " \n",
              "          [[ 0.0356, -0.0692],\n",
              "           [-0.1584, -0.2084]],\n",
              " \n",
              "          [[-0.0436,  0.2504],\n",
              "           [ 0.0542, -0.0068]],\n",
              " \n",
              "          [[-0.1405, -0.3211],\n",
              "           [ 0.2129,  0.3369]],\n",
              " \n",
              "          [[-0.0802,  0.0518],\n",
              "           [ 0.0586, -0.0710]],\n",
              " \n",
              "          [[ 0.0616, -0.1512],\n",
              "           [-0.4311,  0.1028]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0932,  0.0919],\n",
              "           [-0.0515, -0.1465]],\n",
              " \n",
              "          [[-0.0388, -0.0198],\n",
              "           [-0.0786,  0.2544]],\n",
              " \n",
              "          [[ 0.2699,  0.1343],\n",
              "           [ 0.0726,  0.2602]],\n",
              " \n",
              "          [[-0.1179,  0.3716],\n",
              "           [-0.1100,  0.1074]],\n",
              " \n",
              "          [[-0.2539, -0.1331],\n",
              "           [-0.1506, -0.2441]],\n",
              " \n",
              "          [[-0.2548, -0.2294],\n",
              "           [-0.1137, -0.0719]],\n",
              " \n",
              "          [[-0.1678, -0.2941],\n",
              "           [-0.0561, -0.0707]],\n",
              " \n",
              "          [[ 0.1809,  0.2590],\n",
              "           [ 0.3357, -0.0672]]],\n",
              " \n",
              " \n",
              "         [[[-0.0840,  0.0381],\n",
              "           [ 0.1252, -0.2916]],\n",
              " \n",
              "          [[-0.3486, -0.1195],\n",
              "           [ 0.4014,  0.4125]],\n",
              " \n",
              "          [[-0.4321, -0.1153],\n",
              "           [ 0.1103, -0.0543]],\n",
              " \n",
              "          [[ 0.1206,  0.1172],\n",
              "           [-0.0799, -0.2035]],\n",
              " \n",
              "          [[-0.0425,  0.1532],\n",
              "           [ 0.1400,  0.1945]],\n",
              " \n",
              "          [[-0.7349, -0.7131],\n",
              "           [-0.2433, -0.3620]],\n",
              " \n",
              "          [[ 0.0885, -0.1263],\n",
              "           [ 0.2099,  0.1231]],\n",
              " \n",
              "          [[ 0.2183,  0.1714],\n",
              "           [-0.0220, -0.2187]]],\n",
              " \n",
              " \n",
              "         [[[-0.1699, -0.0346],\n",
              "           [ 0.0251,  0.0938]],\n",
              " \n",
              "          [[-0.0086,  0.1200],\n",
              "           [ 0.1168, -0.0344]],\n",
              " \n",
              "          [[ 0.0633,  0.3151],\n",
              "           [ 0.0868,  0.1066]],\n",
              " \n",
              "          [[ 0.0405, -0.0785],\n",
              "           [-0.0172,  0.0945]],\n",
              " \n",
              "          [[-0.2554,  0.0211],\n",
              "           [-0.0491,  0.0473]],\n",
              " \n",
              "          [[-0.0956, -0.1798],\n",
              "           [-0.0290, -0.0447]],\n",
              " \n",
              "          [[ 0.0461,  0.2686],\n",
              "           [-0.1934, -0.1211]],\n",
              " \n",
              "          [[ 0.2892, -0.0940],\n",
              "           [ 0.0731,  0.0971]]],\n",
              " \n",
              " \n",
              "         [[[-0.0994,  0.1216],\n",
              "           [-0.0431, -0.0627]],\n",
              " \n",
              "          [[ 0.2074, -0.0587],\n",
              "           [ 0.1946, -0.0661]],\n",
              " \n",
              "          [[-0.0057,  0.0432],\n",
              "           [ 0.0341,  0.0675]],\n",
              " \n",
              "          [[-0.2935,  0.0339],\n",
              "           [-0.1502, -0.1356]],\n",
              " \n",
              "          [[ 0.0974,  0.0799],\n",
              "           [-0.0368,  0.0890]],\n",
              " \n",
              "          [[-0.4799, -0.5595],\n",
              "           [ 0.4268, -0.0121]],\n",
              " \n",
              "          [[ 0.4072,  0.1139],\n",
              "           [-0.1101, -0.2165]],\n",
              " \n",
              "          [[-0.1882,  0.0762],\n",
              "           [-0.2044, -0.1609]]],\n",
              " \n",
              " \n",
              "         [[[ 0.0765, -0.0747],\n",
              "           [-0.2156,  0.1565]],\n",
              " \n",
              "          [[-0.3215,  0.2626],\n",
              "           [-0.0063, -0.1755]],\n",
              " \n",
              "          [[ 0.4154,  0.0204],\n",
              "           [ 0.1183,  0.0542]],\n",
              " \n",
              "          [[ 0.2570, -0.0611],\n",
              "           [ 0.1746, -0.1139]],\n",
              " \n",
              "          [[ 0.2682,  0.1776],\n",
              "           [ 0.1520,  0.0802]],\n",
              " \n",
              "          [[-0.1312, -0.3066],\n",
              "           [-0.3178, -0.0598]],\n",
              " \n",
              "          [[-0.1800,  0.0704],\n",
              "           [-0.1798, -0.0532]],\n",
              " \n",
              "          [[-0.0574, -0.1539],\n",
              "           [-0.1914, -0.0734]]],\n",
              " \n",
              " \n",
              "         [[[-0.0210, -0.0504],\n",
              "           [-0.1076, -0.2065]],\n",
              " \n",
              "          [[-0.0485,  0.0348],\n",
              "           [ 0.3032,  0.0930]],\n",
              " \n",
              "          [[ 0.1056,  0.0587],\n",
              "           [ 0.0696,  0.0879]],\n",
              " \n",
              "          [[-0.0459, -0.0513],\n",
              "           [ 0.0138, -0.0009]],\n",
              " \n",
              "          [[-0.1771,  0.0225],\n",
              "           [ 0.0807, -0.0836]],\n",
              " \n",
              "          [[-0.3743, -0.4859],\n",
              "           [-0.4494, -0.0827]],\n",
              " \n",
              "          [[ 0.2015,  0.0534],\n",
              "           [ 0.2385,  0.0762]],\n",
              " \n",
              "          [[ 0.1586,  0.1116],\n",
              "           [-0.0694, -0.1473]]],\n",
              " \n",
              " \n",
              "         [[[-0.0163, -0.1500],\n",
              "           [-0.0259, -0.0336]],\n",
              " \n",
              "          [[ 0.2557,  0.2297],\n",
              "           [-0.1615, -0.0081]],\n",
              " \n",
              "          [[ 0.2538, -0.1830],\n",
              "           [ 0.1047, -0.1826]],\n",
              " \n",
              "          [[ 0.0362, -0.0208],\n",
              "           [ 0.1160,  0.0827]],\n",
              " \n",
              "          [[-0.0178,  0.2346],\n",
              "           [ 0.1391,  0.0167]],\n",
              " \n",
              "          [[-0.3093, -0.3621],\n",
              "           [-0.3015, -0.1098]],\n",
              " \n",
              "          [[ 0.2203,  0.0676],\n",
              "           [-0.2191, -0.0678]],\n",
              " \n",
              "          [[-0.1613, -0.3018],\n",
              "           [ 0.0930,  0.0327]]]], device='cuda:0', requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.1275,  0.4325,  0.0955, -0.2475, -0.2300,  0.0816,  0.1084,  0.6637,\n",
              "         -0.3081,  0.0919], device='cuda:0', requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLn5xPedXACY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}