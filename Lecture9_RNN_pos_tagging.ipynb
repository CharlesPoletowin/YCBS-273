{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture9_RNN_pos_tagging.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CharlesPoletowin/YCBS-273/blob/master/Lecture9_RNN_pos_tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qDYUEPIuI3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jzBXYR_NsHI",
        "colab_type": "text"
      },
      "source": [
        "This notebook was inspired from https://github.com/bentrevett/pytorch-sentiment-analysis. Great thanks to the authors!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHSV6fToMlag",
        "colab_type": "text"
      },
      "source": [
        "# Data setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlCfZA09NHLn",
        "colab_type": "code",
        "outputId": "21ad5960-ca2a-486b-dd7c-4b5cd175a611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import GloVe\n",
        "import random\n",
        "\n",
        "SEED = 1234\n",
        "MAX_VOCAB_SIZE = 25_000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Define the fields associated with the sequences.\n",
        "TEXT = data.Field(init_token=\"<bos>\", eos_token=\"<eos>\")\n",
        "UD_TAG = data.Field(init_token=\"<bos>\", eos_token=\"<eos>\")\n",
        "\n",
        "# Download and the load default data.\n",
        "train_data, valid_data, test_data = datasets.UDPOS.splits(fields=(('text', TEXT), ('udtag', UD_TAG)))\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))\n",
        "\n",
        "TEXT.build_vocab(train_data.text, min_freq=3)\n",
        "UD_TAG.build_vocab(train_data.udtag)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading en-ud-v2.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "en-ud-v2.zip: 100%|██████████| 688k/688k [00:00<00:00, 11.0MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extracting\n",
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8zuHKM53wFc",
        "colab_type": "code",
        "outputId": "3fa8ef3e-86bb-4d98-a01e-ef8dd3a44c67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(train_data.fields)\n",
        "print(len(train_data))\n",
        "print(vars(train_data[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': <torchtext.data.field.Field object at 0x7f33ce0e3d30>, 'udtag': <torchtext.data.field.Field object at 0x7f33f0cd4cc0>}\n",
            "12543\n",
            "{'text': ['Al', '-', 'Zaman', ':', 'American', 'forces', 'killed', 'Shaikh', 'Abdullah', 'al', '-', 'Ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'Qaim', ',', 'near', 'the', 'Syrian', 'border', '.'], 'udtag': ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdgr7XeTOKnU",
        "colab_type": "code",
        "outputId": "9032660b-b8db-4800-910b-422160c4ae98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 8780\n",
            "Number of validation examples: 3763\n",
            "Number of testing examples: 2077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj-nB4JvOTth",
        "colab_type": "code",
        "outputId": "fddccf24-bddf-41b3-954a-6ae63425dbba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in UD_TAG vocabulary: {len(UD_TAG.vocab)}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 5220\n",
            "Unique tokens in UD_TAG vocabulary: 21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr-TYgrzObtu",
        "colab_type": "code",
        "outputId": "f134ce33-958c-4ee6-b0c7-8b41ac610354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(UD_TAG.vocab.freqs)\n",
        "\n",
        "print(UD_TAG.vocab.freqs.most_common(20))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'NOUN': 24253, 'PUNCT': 16626, 'VERB': 16199, 'PRON': 13017, 'ADP': 12301, 'DET': 11315, 'PROPN': 9196, 'ADJ': 8800, 'AUX': 8716, 'ADV': 7476, 'CCONJ': 4705, 'PART': 3898, 'NUM': 2825, 'SCONJ': 2696, 'X': 562, 'INTJ': 470, 'SYM': 416})\n",
            "[('NOUN', 24253), ('PUNCT', 16626), ('VERB', 16199), ('PRON', 13017), ('ADP', 12301), ('DET', 11315), ('PROPN', 9196), ('ADJ', 8800), ('AUX', 8716), ('ADV', 7476), ('CCONJ', 4705), ('PART', 3898), ('NUM', 2825), ('SCONJ', 2696), ('X', 562), ('INTJ', 470), ('SYM', 416)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeLEMGzOObwV",
        "colab_type": "code",
        "outputId": "fbc8f257-acee-442b-cdc5-7738bf78eef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', '<bos>', '<eos>', '.', 'the', ',', 'to', 'and', 'a']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3IQx1hrOb0A",
        "colab_type": "code",
        "outputId": "d5f8b22e-be4f-4709-c33f-dbbbc92888e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(UD_TAG.vocab.stoi)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f343bfb26a8>, {'<unk>': 0, '<pad>': 1, '<bos>': 2, '<eos>': 3, 'NOUN': 4, 'PUNCT': 5, 'VERB': 6, 'PRON': 7, 'ADP': 8, 'DET': 9, 'PROPN': 10, 'ADJ': 11, 'AUX': 12, 'ADV': 13, 'CCONJ': 14, 'PART': 15, 'NUM': 16, 'SCONJ': 17, 'X': 18, 'INTJ': 19, 'SYM': 20})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLylZTouMw28",
        "colab_type": "text"
      },
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS9onEg-AJc1",
        "colab_type": "text"
      },
      "source": [
        "## Exercise: Write the bi-directional RNN model and LSTM variant of the same. Test their performance in the given task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHQMm0uOOiuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class RNN_pos_tagger(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        \n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "        return self.fc(output.view(-1, output.shape[-1]))\n",
        "\n",
        "class RNN_deep_pos_tagger(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        \n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, \n",
        "                           num_layers=n_layers)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):#, text_lengths):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        output, hidden = self.rnn(embedded)\n",
        "                \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        \n",
        "        #hidden = [num_layers, batch size, hid dim]\n",
        "        #cell = [num_layers, batch size, hid dim]\n",
        "          \n",
        "        return self.fc(output.view(-1, output.shape[-1]))\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQireMwHiKnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, data_iterator, loss_func):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in data_iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = loss_func(predictions, batch.udtag.view(-1).long())\n",
        "            \n",
        "            acc = accuracy_score(torch.argmax(predictions, dim=1).cpu().detach().numpy(), batch.udtag.view(-1).cpu().numpy())\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc\n",
        "        \n",
        "    return epoch_acc / len(data_iterator), epoch_loss / len(data_iterator)\n",
        "\n",
        "def train_model(model, train_data_iterator, valid_data_iterator, loss_func, optimizer, epochs=5):\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    tic = time.time()\n",
        "    for batch in train_data_iterator:\n",
        "      \n",
        "      predictions = model(batch.text).squeeze(1)\n",
        "      \n",
        "      loss = loss_func(predictions, batch.udtag.view(-1).long())\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "    toc = time.time()\n",
        "    \n",
        "    acc, _ = evaluate(model, valid_data_iterator, loss_func)\n",
        "    toe = time.time()\n",
        "\n",
        "    print('Loss at epoch %d : %f, validation acc : %f | training time : %d sec, evaluation time : %d sec' % (epoch, epoch_loss / len(train_data_iterator), acc, toc-tic, toe - toc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZySqogP3OixH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(model_type, n_layers=2):\n",
        "  INPUT_DIM = len(TEXT.vocab)\n",
        "  EMBEDDING_DIM = 100\n",
        "  HIDDEN_DIM = 256\n",
        "  OUTPUT_DIM = 21\n",
        "  N_LAYERS = n_layers\n",
        "\n",
        "  if model_type == 'rnn':\n",
        "    model = RNN_pos_tagger(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "  elif model_type == 'rnn_deep':\n",
        "    model = RNN_deep_pos_tagger(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS)\n",
        "  elif model_type == 'rnn_deep_bidir':\n",
        "    model = RNN_deep_bidir_pos_tagger(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seh51auaVjob",
        "colab_type": "code",
        "outputId": "e758482a-e6e2-49b5-c024-c9554810ecff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "model = get_model('rnn_deep_bidir')\n",
        "model = model.to(device)\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "loss_func = F.cross_entropy\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "train_model(model, train_iterator, valid_iterator, loss_func, optimizer, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,110,309 trainable parameters\n",
            "Loss at epoch 0 : 0.373077, validation acc : 0.780759 | training time : 2 sec, evaluation time : 0 sec\n",
            "Loss at epoch 1 : 0.191019, validation acc : 0.831823 | training time : 1 sec, evaluation time : 0 sec\n",
            "Loss at epoch 2 : 0.144641, validation acc : 0.859360 | training time : 1 sec, evaluation time : 0 sec\n",
            "Loss at epoch 3 : 0.119310, validation acc : 0.876442 | training time : 1 sec, evaluation time : 0 sec\n",
            "Loss at epoch 4 : 0.098550, validation acc : 0.888743 | training time : 1 sec, evaluation time : 0 sec\n",
            "Loss at epoch 5 : 0.082022, validation acc : 0.897652 | training time : 1 sec, evaluation time : 0 sec\n",
            "Loss at epoch 6 : 0.067951, validation acc : 0.903980 | training time : 1 sec, evaluation time : 0 sec\n",
            "Loss at epoch 7 : 0.056687, validation acc : 0.905779 | training time : 1 sec, evaluation time : 0 sec\n",
            "Loss at epoch 8 : 0.045985, validation acc : 0.909110 | training time : 1 sec, evaluation time : 0 sec\n",
            "Loss at epoch 9 : 0.038476, validation acc : 0.911817 | training time : 1 sec, evaluation time : 0 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4Fw2cjgFKpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}